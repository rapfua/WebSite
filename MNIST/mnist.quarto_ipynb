{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"MNIST\"\n",
        "format: html\n",
        "editor: visual\n",
        "code-fold: true\n",
        "cache: true\n",
        "favicon: images/nine.png\n",
        "---"
      ],
      "id": "d1e9fc03"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: imports\n",
        "\n",
        "import networkx as nx\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import graphlearning as gl  # for get_Gaussian_weight_matrix\n",
        "import igraph as ig         # for get_metric_backbone_igraph\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "import scipy.sparse\n",
        "import numpy as np\n",
        "\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "import pandas as pd"
      ],
      "id": "imports",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Activate the pandas2ri for DataFrame conversion\n",
        "pandas2ri.activate()\n",
        "# Load the Rcpp source file\n",
        "ro.r('Rcpp::sourceCpp(\"../Rcpp/add_edges.cpp\")')\n",
        "\n",
        "# Define the function to call Rcpp\n",
        "add_edges = ro.globalenv['add_edges']\n",
        "compute_ARI = ro.globalenv['compute_ARI']"
      ],
      "id": "6d919fe2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: global variables\n",
        "global_SEED = 42"
      ],
      "id": "global-variables",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: def_get_Gaussian_weight_matrix\n",
        "\n",
        "def get_Gaussian_weight_matrix(X, n_neighbors):\n",
        "    Z = gl.weightmatrix.knn(data=X, k=n_neighbors)  # Gaussian similarity measure\n",
        "    A = (Z + Z.T) / 2\n",
        "    return A"
      ],
      "id": "def_get_Gaussian_weight_matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: def_get_metric_backbone_igraph\n",
        "\n",
        "def get_metric_backbone_igraph(D):\n",
        "    \"\"\"\n",
        "     :param D: networkx distance graph (with weight and proximity edge attribute)\n",
        "     :return: Networkx Metric Backbone subgraph of D\n",
        "    \"\"\"\n",
        "    D_ig = ig.Graph.from_networkx(D)\n",
        "    distances = D_ig.distances(weights='weight')\n",
        "\n",
        "    G = nx.Graph(D)\n",
        "    G.remove_edges_from([(x, y) for x, y, w in G.edges.data('weight') if w > distances[x][y]])\n",
        "    return G"
      ],
      "id": "def_get_metric_backbone_igraph",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: community_detection_on_Euclidean_graphs_FUNCTIONS\n",
        "\n",
        "def euclidean_distance(tuple_1, tuple_2):\n",
        "    return np.linalg.norm(np.array(tuple_1) - np.array(tuple_2))\n",
        "\n",
        "\n",
        "def φ(R):\n",
        "    return lambda r: 1 if r <= R else 0\n",
        "\n",
        "\n",
        "def f(f_r):\n",
        "    return lambda G_distance, u_idx, v_idx: f_r(euclidean_distance(tuple_1=G_distance.nodes[u_idx]['pos'], tuple_2=G_distance.nodes[v_idx]['pos']))\n",
        "  \n",
        "\n",
        "def indicator(condition):\n",
        "    return 1 if condition else 0\n",
        "  \n",
        "\n",
        "def make_F(f_in, f_out):\n",
        "    return lambda G, u_idx, v_idx: indicator(G.nodes[u_idx]['community'] == G.nodes[v_idx]['community']) * f_in(G, u_idx, v_idx) + (1 - indicator(G.nodes[u_idx]['community'] == G.nodes[v_idx]['community'])) * f_out(G, u_idx, v_idx)\n",
        "\n",
        "\n",
        "def make_F_from_R(R1, R2):\n",
        "    return make_F(f(φ(R1)), f(φ(R2)))"
      ],
      "id": "community_detection_on_Euclidean_graphs_FUNCTIONS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: def_produce_distance_graph\n",
        "\n",
        "def produce_distance_graph(X_train, y_train, n_neighbors, SEED=global_SEED):\n",
        "  \n",
        "    rng = np.random.default_rng(SEED)\n",
        "    \n",
        "    n = len(X_train)  # n_nodes\n",
        "  \n",
        "    G = nx.Graph()\n",
        "    \n",
        "    d = {i: X_train[i] for i in range(n)}\n",
        "    \n",
        "    G.add_nodes_from(d.keys())\n",
        "    \n",
        "    nx.set_node_attributes(G, d, 'pos')\n",
        "    my_d = {i: y_train[i] for i in range(n)}\n",
        "    \n",
        "    nx.set_node_attributes(G, {i: y_train[i] for i in range(n)}, 'community')\n",
        "\n",
        "    # edges_to_add = [(u_idx, v_idx) for u_idx in range(n) for v_idx in range(u_idx + 1, n) if F(G, u_idx, v_idx) == 1]\n",
        "    # \n",
        "    # G.add_edges_from(edges_to_add)\n",
        "    # \n",
        "    # \n",
        "    # \n",
        "    # if framework == 'gaussian':\n",
        "    #     nx.set_node_attributes(G, {node: 1 if node + 1 > n else 0 for node in G.nodes}, 'community')\n",
        "    # \n",
        "    #     col_slice = slice(1, samples.shape[1] + 1)\n",
        "    \n",
        "    W = get_Gaussian_weight_matrix(X_train, n_neighbors)\n",
        "        # Call the Rcpp function to get the edges\n",
        "\n",
        "    # for i in range(n):\n",
        "    #     for j in range(i + 1, n):\n",
        "    #         if i % 100 == 0 and j == i + 1:\n",
        "    #             print(f'Processing node {i}')\n",
        "    #         w = W[i, j]\n",
        "    #         if w > 0:\n",
        "    #             G.add_edge(i, j, weight=1 / w - 1)\n",
        "    # \n",
        "    # return G\n",
        "    # \n",
        "    W_dense = W.toarray()\n",
        "    \n",
        "    W_r = ro.r.matrix(W_dense, nrow=W_dense.shape[0], ncol=W_dense.shape[1])\n",
        "    \n",
        "    edges_df = add_edges(W_r)\n",
        "    \n",
        "    # # Convert R DataFrame to Python pandas DataFrame\n",
        "    # edges = pandas2ri.ri2py(edges_df)\n",
        "    \n",
        "    # Convert the R DataFrame to a pandas DataFrame using the updated conversion mechanism\n",
        "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
        "        edges = ro.conversion.rpy2py(edges_df)\n",
        "\n",
        "    # Add edges to the graph\n",
        "    for index, row in edges.iterrows():\n",
        "        G.add_edge(int(row['from']), int(row['to']), weight=row['weight'])\n",
        "        \n",
        "    return G\n"
      ],
      "id": "def_produce_distance_graph",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: inter_and_intra_community_proportion_functions\n",
        "\n",
        "\n",
        "def get_inter_proportion(G):\n",
        "  \n",
        "  nominator = 0\n",
        "  \n",
        "  for u, v in G.edges():\n",
        "    if G.nodes[u]['community'] != G.nodes[v]['community']:\n",
        "      nominator += 1\n",
        "      \n",
        "  denominator = G.number_of_edges()\n",
        "      \n",
        "  res = nominator / denominator\n",
        "  \n",
        "  return res\n",
        "\n",
        "\n",
        "def get_intra_proportion(G):\n",
        "  return 1 - get_inter_proportion(G)"
      ],
      "id": "inter_and_intra_community_proportion_functions",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: def_get_similarity_def_draw\n",
        "\n",
        "def get_similarity(X_train_flat, n_neighbors, true_labels, b_original=True, MB=None):\n",
        "    A = None\n",
        "    \n",
        "    if b_original:\n",
        "        A = get_Gaussian_weight_matrix(X_train_flat, n_neighbors)\n",
        "    else:\n",
        "        A = nx.adjacency_matrix(MB, nodelist=[i for i in range(MB.number_of_nodes())], weight='proximity')\n",
        "        A = scipy.sparse.csr_matrix(A)\n",
        "        \n",
        "    SC = SpectralClustering(n_clusters=10, affinity='precomputed')\n",
        "    pred_labels = SC.fit_predict(A)\n",
        "    \n",
        "    # Convert true_labels and pred_labels to Rcpp IntegerVectors\n",
        "    true_labels_r = ro.IntVector(true_labels)\n",
        "    pred_labels_r = ro.IntVector(pred_labels)\n",
        "    \n",
        "    # Call the Rcpp function to compute ARI\n",
        "    similarity = compute_ARI(true_labels_r, pred_labels_r)\n",
        "    \n",
        "    return similarity\n",
        "  \n",
        "# def get_similarity(X_train_flat, n_neighbors, true_labels, b_original=True, MB=None):\n",
        "#   \n",
        "#     A = None\n",
        "#     \n",
        "#     if b_original:\n",
        "#         A = get_Gaussian_weight_matrix(X_train_flat, n_neighbors)\n",
        "#     else:\n",
        "#         A = nx.adjacency_matrix(MB, nodelist=[i for i in range(MB.number_of_nodes())], weight='proximity')\n",
        "#         A = scipy.sparse.csr_matrix(A)\n",
        "#         \n",
        "#     \n",
        "#     SC = SpectralClustering(n_clusters=10, affinity='precomputed')\n",
        "#     pred_labels = SC.fit_predict(A)\n",
        "#     \n",
        "#     print(max(pred_labels))\n",
        "#     print(pred_labels[:10])\n",
        "#     print(true_labels[:10])\n",
        "#     print()\n",
        "#     \n",
        "#     similarity  = adjusted_rand_score(true_labels, pred_labels)\n",
        "#     \n",
        "#     return similarity\n",
        "\n",
        "\n",
        "def get_similarities(G, MB, X_train_flat, n_neighbors, n_clusters, affinity='precomputed'):\n",
        "  \n",
        "    pos = nx.get_node_attributes(G, 'pos')  # Extract node positions\n",
        "    \n",
        "    true_labels = list(nx.get_node_attributes(G, 'community').values())\n",
        "\n",
        "    \n",
        "      \n",
        "    similarity_original = get_similarity(X_train_flat, n_neighbors, true_labels)\n",
        "    \n",
        "    similarity_mb = get_similarity(\n",
        "      X_train_flat=None,\n",
        "      n_neighbors=None,\n",
        "      true_labels=true_labels,\n",
        "      b_original=False,\n",
        "      MB=MB\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    return similarity_original, similarity_mb\n",
        "  \n",
        "\n",
        "def print_similarities(G, MB, X_train_flat, n_neighbors, n_clusters, affinity='precomputed'):\n",
        "    similarity_original, similarity_mb = get_similarities(G, MB, X_train_flat, n_neighbors, n_clusters, affinity)\n",
        "    print(f'Original SC ARI: {similarity_original * 100:.2f}%')\n",
        "    print(f'Metric Backbone SC ARI: {similarity_mb * 100:.2f}%')"
      ],
      "id": "def_get_similarity_def_draw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: N_images\n",
        "\n",
        "n_images = 1000\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (_, _) = mnist.load_data()  # X_train is 28x28=784 <class 'numpy.ndarray'>\n",
        "print(len(X_train))\n",
        "\n",
        "X_train = X_train[:n_images] / 255.0\n",
        "\n",
        "# Normalization => maximum euclidean distance between two images is:\n",
        "# sqrt(\\sum_{i=1}^{784} (1 - 0)^2) = sqrt(784) = 28.\n",
        "# We now choose R1 & R2 with this in mind.\n",
        "\n",
        "F = make_F_from_R(R1=12, R2=8)\n",
        "\n",
        "y_train = y_train[:n_images]\n",
        "\n",
        "# Print 4 images in a row\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.imshow(X_train[i], cmap='gray')\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "N_images",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: flatten the images\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "#print(X_train_flat[0])"
      ],
      "id": "flatten-the-images",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: test_produce_distance_graph\n",
        "\n",
        "\n",
        "G = produce_distance_graph(X_train_flat, y_train, n_neighbors=500)"
      ],
      "id": "test_produce_distance_graph",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: draw the graph\n",
        "\n",
        "\n",
        "# col_slice = slice(1, samples.shape[1] + 1)\n",
        "# \n",
        "#W = get_Gaussian_weight_matrix(X=X_train_flat, n_neighbors=500)\n",
        "# \n",
        "#edges = list(G.edges())\n",
        "\n",
        "# print(f'number of edges: {len(edges)}')\n",
        "\n",
        "#weights = {(u, v): 1 / W[u, v] - 1 if W[u, v] > 0 else float('inf') for u, v in edges}\n",
        "\n",
        "#nx.set_edge_attributes(G, weights, 'weight')\n",
        "\n",
        "# print(f'edge attributes: {G.edges.data()}')\n",
        "# Get a list of all edge attribute names\n",
        "#edge_attributes = list(next(iter(G.edges(data=True)))[2].keys())\n",
        "#print(\"Edge Attributes:\", edge_attributes)\n",
        " \n",
        "mb_igraph = get_metric_backbone_igraph(G)"
      ],
      "id": "draw-the-graph",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: remove isolated nodes\n",
        "\n",
        "isolated_nodes_G = list(nx.isolates(G))\n",
        "G.remove_nodes_from(isolated_nodes_G)\n",
        "\n",
        "isolated_nodes_mb_igraph = list(nx.isolates(mb_igraph))\n",
        "mb_igraph.remove_nodes_from(isolated_nodes_mb_igraph)\n",
        "\n",
        "\n",
        "\n",
        "if not isolated_nodes_G:\n",
        "    print(\"G has no isolated nodes\")\n",
        "else:\n",
        "    print(\"G has isolated nodes\")\n",
        "    \n",
        "# for elt in isolated_nodes:\n",
        "#     print(f'Isolated node: {elt}')\n",
        "\n",
        "if not isolated_nodes_mb_igraph:\n",
        "    print(\"MB has no isolated nodes\")\n",
        "else:\n",
        "    print(\"MB has isolated nodes\")"
      ],
      "id": "remove-isolated-nodes",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| label: print the results\n",
        "\n",
        "print(f'Original number of edges: {G.number_of_edges()}')\n",
        "print(f'Original inter-proportion: {get_inter_proportion(G) * 100:.2f}%\\n')\n",
        "\n",
        "print(f'Metric Backbone number of edges: {mb_igraph.number_of_edges()}')\n",
        "print(f'Metric Backbone inter-proportion: {get_inter_proportion(mb_igraph) * 100:.2f}%\\n')\n",
        "\n",
        "print('--------------------------')\n",
        "\n",
        "print_similarities(G, mb_igraph, X_train_flat, n_neighbors=500, n_clusters=2, affinity='precomputed')\n"
      ],
      "id": "print-the-results",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: toy example for removing isolated nodes\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create a toy example graph with 10 nodes\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(range(10))\n",
        "\n",
        "# Add some edges (nodes 0-5 are connected, 6-9 are isolated)\n",
        "edges = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n",
        "G.add_edges_from(edges)\n",
        "\n",
        "# Plot the graph before removing isolated nodes\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "nx.draw(G, with_labels=True, node_color='skyblue', font_weight='bold')\n",
        "plt.title(\"Before removing isolated nodes\")\n",
        "\n",
        "# Find and remove isolated nodes\n",
        "isolated_nodes = list(nx.isolates(G))\n",
        "G.remove_nodes_from(isolated_nodes)\n",
        "\n",
        "# Plot the graph after removing isolated nodes\n",
        "plt.subplot(1, 2, 2)\n",
        "nx.draw(G, with_labels=True, node_color='lightgreen', font_weight='bold')\n",
        "plt.title(\"After removing isolated nodes\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Isolated nodes removed: {isolated_nodes}\")"
      ],
      "id": "toy-example-for-removing-isolated-nodes",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/cloud/python/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}