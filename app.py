# This file generated by Quarto; do not edit by hand.
# shiny_mode: core

from __future__ import annotations

from pathlib import Path
from shiny import App, Inputs, Outputs, Session, ui

import shiny
import random
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D
from pipe import sort


import numpy as np
from numpy.random import poisson, uniform

import scipy.sparse

from sklearn.cluster import SpectralClustering
from sklearn.metrics import adjusted_rand_score


from shiny.express import render, ui

import networkx as nx       # for get_metric_backbone_igraph
import graphlearning as gl  # for get_Gaussian_weight_matrix
import igraph as ig         # for get_metric_backbone_igraph

# ========================================================================




def server(input: Inputs, output: Outputs, session: Session) -> None:
    global_SEED = 42
    SC = SpectralClustering(n_clusters=2, affinity='precomputed')

    # ========================================================================

    class Pipe:
        def __init__(self, function):
            self.function = function

        def __ror__(self, other):
            return self.function(other)

    # EXAMPLE USAGE: define custom functions to use with the pipe

    # @Pipe
    # def add_one(x):
    #     return x + 1
    # 
    # @Pipe
    # def square(x):
    #     return x * x
    # 
    # result = 5 | add_one | square
    # print(result)  # Output: 36

    # ========================================================================

    class StringIndexed3DArray:
        def __init__(self, array, dim1_labels, dim2_labels, dim3_labels):
            self.array = array
            # Create dictionaries to map strings to indices for each dimension
            self.index_map_dim1 = {label: i for i, label in enumerate(dim1_labels)}
            self.index_map_dim2 = {label: i for i, label in enumerate(dim2_labels)}
            self.index_map_dim3 = {label: i for i, label in enumerate(dim3_labels)}
            self.dim1_labels = dim1_labels
            self.dim2_labels = dim2_labels
            self.dim3_labels = dim3_labels

        def __getitem__(self, indices):
            row_label, col_label, depth_label = indices
            # Convert string labels to indices
            row = self._convert_to_index(row_label, self.index_map_dim1)
            col = self._convert_to_index(col_label, self.index_map_dim2)
            depth = self._convert_to_index(depth_label, self.index_map_dim3)
            # Access the value or slice from the array
            return self.array[row, col, depth]
    
        def _convert_to_index(self, label, index_map):
            if isinstance(label, slice):
                # If it's a slice, return the slice itself
                return slice(
                    self.index_map_dim1.get(label.start, 0) if label.start else None,
                    self.index_map_dim1.get(label.stop, None),
                    label.step
                )
            elif isinstance(label, str):
                # If it's a string, convert it to the index using the map
                return index_map[label]
            else:
                return label  # Allow passing integers directly

        def __setitem__(self, indices, value):
            row_label, col_label, depth_label = indices
            # Convert string labels to indices
            row = self.index_map_dim1[row_label]
            col = self.index_map_dim2[col_label]
            depth = self.index_map_dim3[depth_label]
            # Set the value in the array
            self.array[row, col, depth] = value
        
        
        def __str__(self):
            result = []
            for i, dim1_label in enumerate(self.dim1_labels):
                result.append(f"\nDim1 ({dim1_label}):\n")
                for j, dim2_label in enumerate(self.dim2_labels):
                    row = f"Dim2 ({dim2_label}): "
                    row += " ".join(f"{self.array[i, j, k]:.2f}" for k in range(len(self.dim3_labels)))
                    result.append(row)
            return "\n".join(result)
      
      
        def AVG_ARI_LIST(self, n_neighbors_LIST, framework_str):
            return [self[n_neighbors - 3, framework_str, slice(None)].mean() for n_neighbors in n_neighbors_LIST]
      
      
        def STD_ARI_LIST(self, n_neighbors_LIST, framework_str):
            return [self[n_neighbors - 3, framework_str, slice(None)].std() for n_neighbors in n_neighbors_LIST]


    # ========================================================================

    def get_Gaussian_weight_matrix(X, n_neighbors):
        Z = gl.weightmatrix.knn(X, n_neighbors)  # Gaussian similarity measure
        A = (Z + Z.T) / 2
        return A

    # ========================================================================

    def get_metric_backbone_igraph(D):
        """
         :param D: networkx distance graph (with weight and proximity edge attribute)
         :return: Networkx Metric Backbone subgraph of D
        """
        D_ig = ig.Graph.from_networkx(D)
        distances = D_ig.distances(weights='weight')

        G = nx.Graph(D)
        G.remove_edges_from([(x, y) for x, y, w in G.edges.data('weight') if w > distances[x][y]])
        return G

    # ========================================================================

    def euclidean_distance(tuple_1, tuple_2):
        return np.linalg.norm(np.array(tuple_1) - np.array(tuple_2))


    def φ(R):
        return lambda r: 1 if r <= R else 0


    def f(f_r):
        return lambda G_distance, u_idx, v_idx: f_r(euclidean_distance(tuple_1=G_distance.nodes[u_idx]['pos'], tuple_2=G_distance.nodes[v_idx]['pos']))
  

    def indicator(condition):
        return 1 if condition else 0
  

    def make_F(f_in, f_out):
        return lambda G, u_idx, v_idx: indicator(G.nodes[u_idx]['community'] == G.nodes[v_idx]['community']) * f_in(G, u_idx, v_idx) + (1 - indicator(G.nodes[u_idx]['community'] == G.nodes[v_idx]['community'])) * f_out(G, u_idx, v_idx)


    # ========================================================================

    def get_inter_proportion(G):
  
      nominator = 0
  
      for u, v in G.edges():
        if G.nodes[u]['community'] != G.nodes[v]['community']:
          nominator += 1
      
      denominator = G.number_of_edges()
      
      res = nominator / denominator
  
      return res


    def get_intra_proportion(G):
      return 1 - get_inter_proportion(G)

    # ========================================================================

    def produce_samples(n, d , type_samples, mu_x2=None, SEED=global_SEED):
    
        rng = np.random.default_rng(SEED)
  
        n_rows = n * d  # one row per node
        samples = np.empty((n_rows, d + 1))
        samples[:, 0] = np.arange(len(samples))
    
    
        if type_samples == "gaussian":
    
            col_slice = slice(1, samples.shape[1] + 1)
    
            idx = 0
            for last_row in range(0, n_rows, n):  # step size is n
                mean_val = mu_x2 * idx
                row_slice = slice(last_row, last_row + n)
                samples[row_slice, col_slice] = rng.multivariate_normal(
                    mean=np.insert(np.zeros(d - 1), 0, mean_val), cov=np.eye(d), size=n
                )
                idx += 1
    
    
        elif type_samples == "uniform":
      
            d_root_n = n_rows ** (1 / d)
            samples[:, 1:] = d_root_n  * rng.uniform(size=(n_rows, d))  # type(.)    : np.ndarray
                                                                         # np.shape(.): (N_n, d)
      
        else:
            raise ValueError("type_samples must be either 'gaussian' or 'uniform'")
      
    
        return samples

    # ========================================================================

    def produce_distance_graph(samples, n, n_communities, n_neighbors=None, framework='gaussian', SEED=global_SEED, F=None, R1=None, R2=None):
  
        rng = np.random.default_rng(SEED)
  
        G = nx.Graph()
    
        d = {int(row[0]): (row[1], row[2]) for row in samples}
    
        G.add_nodes_from(d.keys())
        nx.set_node_attributes(G, d, 'pos')
    
        n_nodes = n * n_communities
        
        if framework == 'gaussian':
            nx.set_node_attributes(G, {node: 1 if node + 1 > n else 0 for node in G.nodes}, 'community')
    
            col_slice = slice(1, samples.shape[1] + 1)
    
            W = get_Gaussian_weight_matrix(samples[:, col_slice], n_neighbors)
    
            for i in range(n_nodes):
                for j in range(i + 1, n_nodes):
                    w = W[i, j]
                    if w > 0:
                        G.add_edge(i, j, weight=1 / w - 1)
                
    
        elif framework == 'ABBE':
    
            community_labels = np.array(range(1, n_communities + 1))
            nx.set_node_attributes(G, {node: rng.choice(community_labels) for node in G.nodes}, 'community')
        
        
            edges_to_add = [(u_idx, v_idx) for u_idx in range(n_nodes) for v_idx in range(u_idx + 1, n_nodes) if F(G, u_idx, v_idx) == 1]
        
            G.add_edges_from(edges_to_add)
        
        elif framework == 'hybrid':
            nx.set_node_attributes(G, {node: 1 if node + 1 > n else 0 for node in G.nodes}, 'community')
        
        
 
            edges_to_add = [(u_idx, v_idx) for u_idx in range(n_nodes) for v_idx in range(u_idx + 1, n_nodes) if F(G, u_idx, v_idx) == 1]
        
            G.add_edges_from(edges_to_add)

        return G


    # ========================================================================

    # Helper functions to add legend
    def produce_patch(color, framework='gaussian', mu_x2=None, plus_or_minus_one=None):
      if framework == 'gaussian':
        return plt.Line2D(
            [0],
            [0], 
            marker='o', 
            color='w', 
            markerfacecolor=color, 
            markersize=8, 
            label=f'X-mean: {round(mu_x2)}'
        )
      elif framework == 'ABBE':
        return plt.Line2D(
            [0],
            [0], 
            marker='o', 
            color='w', 
            markerfacecolor=color, 
            markersize=8, 
            label=f'Community label: {plus_or_minus_one}'
        )


    # ========================================================================

    def get_predColors_similarity(samples, col_slice, n_neighbors, true_labels, b_original=True, MB=None):
  
        A = None
    
        if b_original:
            A = get_Gaussian_weight_matrix(samples[:, col_slice], n_neighbors)
        else:
            A = nx.adjacency_matrix(MB, nodelist=[i for i in range(MB.number_of_nodes())], weight='proximity')
            A = scipy.sparse.csr_matrix(A)
        
        pred_labels = SC.fit_predict(A)
        pred_colors = ['red' if label == pred_labels[0] else 'blue' for label in pred_labels]
        similarity  = adjusted_rand_score(true_labels, pred_labels)
    
        if b_original:
            print(f"Adjusted Rand Score on Original Graph: {similarity * 100}")
        else:
            print(f"Adjusted Rand Score on MB : {similarity * 100}")
        
        return pred_colors, similarity


    def draw(G, MB, samples, n_neighbors, axs, n_clusters, L_idx=[0, 1], affinity='precomputed'):
  
        pos = nx.get_node_attributes(G, 'pos')  # Extract node positions
    
        true_labels = list(nx.get_node_attributes(G, 'community').values())
        true_colors = ['red' if label == true_labels[0] else 'blue' for label in true_labels]

        col_slice = slice(1, samples.shape[1] + 1)

        SC = SpectralClustering(n_clusters=n_clusters, affinity=affinity)
    
      
        pred_colors_original, similarity_original = get_predColors_similarity(
          samples,
          col_slice,
          n_neighbors,
          true_labels
        )
    
        pred_colors_mb, similarity_mb = get_predColors_similarity(
          samples=None,
          col_slice=None,
          n_neighbors=None,
          true_labels=true_labels,
          b_original=False,
          MB=MB
        )



        nx.draw(G, pos, node_color=true_colors, node_size=5, ax=axs[L_idx[0], 0], edge_color='lightgray')
        nx.draw(MB, pos, node_color=true_colors, node_size=5, ax=axs[L_idx[0], 1], edge_color='lightgray')
    
        nx.draw(G, pos, node_color=pred_colors_original, node_size=5, ax=axs[L_idx[1], 0], edge_color='lightgray')
        nx.draw(MB, pos, node_color=pred_colors_mb, node_size=5, ax=axs[L_idx[1], 1], edge_color='lightgray')
    
        return similarity_original, similarity_mb

    # ========================================================================

    ui.markdown("## Percolation Demo")

    ui.input_select("p", "Probability:",
                    choices=[x / 100 for x in range(1, 100)],
                    selected=0.5,
                    width=10
    )
    ui.input_select("grid_size", "Number of nodes in each dimension:",
                    choices=[x for x in range(2, 101)],
                    selected=10
    )

    # ========================================================================

    @render.plot
    def percolation_plot():
  
        p = float(input.p())
        grid_size = int(input.grid_size())
        G = nx.grid_2d_graph(grid_size, grid_size)
        pos = {(x, y): (x, y) for x, y in G.nodes()}
    
        # needs to be this high in code
        plt.figure(figsize=(6, 6))  
    
        for (u, v) in G.edges():
            edge_color = 'red' if random.random() < p else 'black'
            edge_width = 3 if edge_color == 'red' else 1  # Thicker for red edges
            nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], edge_color=edge_color, width=edge_width)
    
        nx.draw_networkx_nodes(G, pos, node_size=0)
    
        legend_elements = [
            Line2D([0], [0], color='red', lw=3, label  ='open   & w(e) = 1'),
            Line2D([0], [0], color='black', lw=1, label='closed & w(e) = 0'),
        ]
    
    
        plt.legend(handles=legend_elements, bbox_to_anchor=(1.4, 0.96))
        plt.gca().set_aspect('equal')
        plt.axis('off')
        plt.title(f"{grid_size}x{grid_size} Grid with p = {p:.2f}", fontsize=14)
        plt.text(
          0.5,
          -0.05, 
          'Figure 1: each edge is open with probability p.',
          fontsize=12,
          ha='center',
          va='center', 
          transform=plt.gca().transAxes
        )

        # Adjust layout to ensure the caption fits within the figure area
        plt.tight_layout()

    # ========================================================================

    input_select_width = 10

    L = list(range(100, 501, 100))
    L.insert(0, 50)

    ui.input_select("n", "Number of nodes in each cluster:",
                    choices=L,
                    selected=50,
                    width=input_select_width
    )

    ui.input_select("d", "Number of dimensions & communities:",
                    choices=list((2, 3, 4)),
                    selected=2,
                    width=input_select_width
    )

    # for graph creation (& spectral clustering)
    ui.input_select("n_neighbors", "Number of nearest neighbors ",
                    choices=list(range(5, 21)),
                    selected=10,
                    width=input_select_width
    )

    ui.input_select("mu_x2", "Mean of the second Gaussian with respect to the x-axis:",
                    choices=list(range(1, 21)),
                    selected=3,
                    width=input_select_width
    )


    ui.input_select("λ", "Intensity parameter (N_n ~ Poisson(λ * n)):",
                    choices=[1],
                    selected=1,
                    width=input_select_width
    )

    ui.input_select("R_1", "Big radius for intra-community edges:",
                    choices=list(range(1, 11)),
                    selected=3,
                    width=input_select_width
    )

    ui.input_select("R_2", "Small radius for inter-community edges:",
                    choices=[1, 1.5, 2, 2.5, 3],
                    selected=[1.5],
                    width=input_select_width
    )

    # ========================================================================

    @render.plot
    def normals_nNodes_dDimensions_PLOT():
    
        n           = int(input.n())
        d           = int(input.d())
        n_clusters  = d
        n_neighbors           = int(input.n_neighbors())
        mu_x2       = float(input.mu_x2())
        #n_neighbors = int(input.n_neighbors())
        # n_neighbors = k
        λ           = int(input.λ())

        R_1         = float(input.R_1())  
        R_2         = float(input.R_2())
        R_1, R_2 = max(R_1, R_2), min(R_1, R_2)
        f_in_r  = φ(R_1)
        f_out_r = φ(R_2)
        f_in  = f(f_in_r)
        f_out = f(f_out_r)
    
        F = make_F(f_in, f_out)


        # Generate samples separately
        samples_gaussian = produce_samples(n, d, type_samples="gaussian", mu_x2=mu_x2)

        # Update G_distance separately
        G_distance = produce_distance_graph(samples_gaussian, n, d, n_neighbors)
        mb_igraph = get_metric_backbone_igraph(G_distance)

        # Now handle plotting
        fig, axs = plt.subplots(4, 2, figsize=(24, 12))
    
        similarity_original, similarity_mb = draw(G_distance, mb_igraph, samples_gaussian, n_neighbors, axs, n_clusters)

        ############## ABBE ################
    
        SC = SpectralClustering(n_clusters=n_clusters, affinity='precomputed')

        samples_uniform = produce_samples(n, d, type_samples="uniform")
        G_distance_ABBE = produce_distance_graph(samples_uniform, n, d, framework='ABBE', F=F)

        col_slice = slice(1, samples_uniform.shape[1] + 1)

        W = get_Gaussian_weight_matrix(samples_uniform[:, col_slice], n_neighbors)

        edges = list(G_distance_ABBE.edges())
        weights = {(u, v): 1 / W[u, v] - 1 if W[u, v] > 0 else float('inf') for u, v in edges}
        nx.set_edge_attributes(G_distance_ABBE, weights, 'weight')

        mb_igraph_ABBE = get_metric_backbone_igraph(G_distance_ABBE)

        similarity_original_ABBE, similarity_mb_ABBE = draw(G_distance_ABBE, mb_igraph_ABBE, samples_uniform, n_neighbors, axs, n_clusters, L_idx=[2, 3])

        for i in range(4):
            for j in range(2):
                ax = axs[i, j]
                ax.set_xlabel('X-axis')
                ax.set_ylabel('Y-axis')
                ax.axis('equal')
                ax.axis('on')
                ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)
                if i < 2:
                    ax.legend(handles=[produce_patch(color='red', framework='gaussian', mu_x2=0), produce_patch(color='blue', framework='gaussian', mu_x2=mu_x2)])
                else:
                    ax.legend(handles=[produce_patch(color='red', framework='ABBE',  plus_or_minus_one=1), produce_patch(color='blue', framework='ABBE', plus_or_minus_one=-1)])


        axs[0, 0].set_title(f'Gaussian Samples with {n} nodes in each cluster, inter-proportion: {get_inter_proportion(G_distance) * 100:.2f}%')
        axs[0, 1].set_title(f'Metric Backbone, inter-proportion: {get_inter_proportion(mb_igraph) * 100:.2f}%')
    
        axs[1, 0].set_title(f'SC: Gaussian Samples with {n} nodes in each cluster, ARI: {similarity_original * 100:.2f}%')
        axs[1, 1].set_title(f'SC: Metric Backbone, ARI: {similarity_mb * 100:.2f}%')
    
    
        axs[2, 0].set_title(f'ABBE original {G_distance_ABBE.number_of_edges()} edges, inter-proportion: {get_inter_proportion(G_distance_ABBE) * 100:.2f}%')
        axs[2, 1].set_title(f'ABBE MB {mb_igraph_ABBE.number_of_edges()} edges, inter-proportion: {get_inter_proportion(mb_igraph_ABBE) * 100:.2f}%')
        axs[3, 0].set_title(f'SC: ABBE original, ARI: {similarity_original_ABBE * 100:.2f}%')
        axs[3, 1].set_title(f'SC: ABBE MB, ARI: {similarity_mb_ABBE * 100:.2f}%')


    # ========================================================================

    input_select_width = 10

    L = list(range(100, 501, 100))
    L.insert(0, 50)

    ui.input_select("n100", "Number of nodes in each cluster:",
                    choices=L,
                    selected=50,
                    width=input_select_width
    )

    ui.input_select("d100", "Number of dimensions & communities:",
                    choices=list((2, 3, 4)),
                    selected=2,
                    width=input_select_width
    )

    # for graph creation (& spectral clustering)
    ui.input_select("n_neighbors100", "Number of nearest neighbors ",
                    choices=list(range(5, 21)),
                    selected=10,
                    width=input_select_width
    )

    # ui.input_select("n_neighbors", "Number of nearest neighbors for spectral clustering:",
    #                 choices=list(range(3, 16)),
    #                 selected=4,
    #                 width=input_select_width
    # )

    ui.input_select("mu_x2100", "Mean of the second Gaussian with respect to the x-axis:",
                    choices=list(range(1, 21)),
                    selected=3,
                    width=input_select_width
    )


    ui.input_select("λ100", "Intensity parameter (N_n ~ Poisson(λ * n)):",
                    choices=[1],
                    selected=1,
                    width=input_select_width
    )

    ui.input_select("R_1100", "Big radius for intra-community edges:",
                    choices=[round(i * 0.01, 2) for i in range(1, 201)],
                    selected= 1,
                    width=input_select_width
    )

    ui.input_select("R_2100", "Small radius for inter-community edges:",
                    choices=[round(i * 0.01, 2) for i in range(1, 101)],
                    selected=0.5,
                    width=input_select_width
    )

    # ========================================================================

    @render.plot
    def graph_gaussian_clusters_ABBE_prediction_PLOT():
  
    
        n           = int(input.n100())
        d           = int(input.d100())
        n_clusters  = d
        n_neighbors = int(input.n_neighbors100())
        mu_x100       = float(input.mu_x2100())
        λ           = int(input.λ100())

        F = make_F(f(φ(float(input.R_1100()))), f(φ(float(input.R_2100()))))
    
        # Generate samples separately
        samples = produce_samples(n, d, type_samples="gaussian", mu_x2=mu_x100)
    
        # Update G_distance separately
        G = produce_distance_graph(samples, n, d, framework='hybrid', F=F)

        col_slice = slice(1, samples.shape[1] + 1)

        W = get_Gaussian_weight_matrix(samples[:, col_slice], n_neighbors)

        edges = list(G.edges())
        weights = {(u, v): 1 / W[u, v] - 1 if W[u, v] > 0 else float('inf') for u, v in edges}
        nx.set_edge_attributes(G, weights, 'weight')
    
        mb_igraph = get_metric_backbone_igraph(G)
    
        fig, axs = plt.subplots(2, 2, figsize=(12, 12))
    
        similarity_original, similarity_mb = draw(
          G,
          mb_igraph,
          samples,
          n_neighbors,
          axs,
          n_clusters,
          L_idx=[0, 1]
        )


        for i in range(2):
            for j in range(2):
                ax = axs[i, j]
                ax.set_xlabel('X-axis')
                ax.set_ylabel('Y-axis')
                ax.axis('equal')
                ax.axis('on')
                ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)
                ax.legend(
                  handles=[produce_patch(color='red', framework='gaussian', mu_x2=0),
                           produce_patch(color='blue', framework='gaussian', mu_x2=mu_x100)]
                 )


        axs[0, 0].set_title(f'Gaussian Samples with {n} nodes in each cluster, inter-proportion: {get_inter_proportion(G) * 100:.2f}%')
        axs[0, 1].set_title(f'Metric Backbone, inter-proportion: {get_inter_proportion(mb_igraph) * 100:.2f}%')
    
        axs[1, 0].set_title(f'SC: Gaussian Samples with {n} nodes in each cluster, ARI: {similarity_original * 100:.2f}%')
        axs[1, 1].set_title(f'SC: Metric Backbone, ARI: {similarity_mb * 100:.2f}%')


    # ========================================================================

    input_select_width = 10

    L = list(range(100, 501, 100))
    L.insert(0, 50)

    ui.input_select('n_simulations4', 'Number of simulations:',
                    choices=[1, 3] + list(range(10, 101, 10)),
                    selected=3,
                    width=input_select_width
    )

    ui.input_select("n4", "Number of nodes in each cluster:",
                    choices=L,
                    selected=100,
                    width=input_select_width
    )

    ui.input_select("d4", "Number of dimensions & communities:",
                    choices=list((2, 3, 4)),
                    selected=2,
                    width=input_select_width
    )


    ui.input_select("mu_x24", "Mean of the second Gaussian with respect to the x-axis:",
                    choices=list(range(1, 21)),
                    selected=3,
                    width=input_select_width
    )





    ui.input_select("R_14", "Big radius for intra-community edges:",
                    choices=[round(i * 0.01, 2) for i in range(1, 201)],
                    selected= 1,
                    width=input_select_width
    )

    ui.input_select("R_24", "Small radius for inter-community edges:",
                    choices=[round(i * 0.01, 2) for i in range(1, 101)],
                    selected=0.5,
                    width=input_select_width
    )


    # ========================================================================

    @render.plot
    def graph_mu_fixed_n_neighbors_varying_PLOT_HYBRID():
  
        λ           = 1

        F = make_F(f(φ(float(input.R_14()))), f(φ(float(input.R_24()))))
    
  
        n_simulations = int(input.n_simulations4())
    
        n           = int(input.n4())
        d           = int(input.d4())
        n_clusters  = d
        mu_x2       = float(input.mu_x24())
    
        n_neighbors_LIST = list(range(3, 51))

        fig, axs = plt.subplots(2, 1, figsize=(6, 12))
    
        dim3_labels = [f'similarity_{i}' for i in range(n_simulations)]
    
        array_3d = StringIndexed3DArray(array=np.zeros((len(n_neighbors_LIST), 2, n_simulations)), dim1_labels=n_neighbors_LIST, dim2_labels=['ARI_original', 'ARI_MB'], dim3_labels=dim3_labels)
    
        for i in range(n_simulations):
            print()
            print('Simulation:', i + 1, 'out of', n_simulations, 'started')
            print()
        
            samples = produce_samples(n, d, type_samples="gaussian", mu_x2=mu_x2, SEED=i)
            col_slice = slice(1, samples.shape[1] + 1)
        
        
        
            for j, n_neighbors in enumerate(n_neighbors_LIST):
                # Update G_distance separately
                G = produce_distance_graph(samples, n, d, framework='hybrid', F=F)
        
                W = get_Gaussian_weight_matrix(samples[:, col_slice], n_neighbors)
        
                edges = list(G.edges())
                weights = {(u, v): 1 / W[u, v] - 1 if W[u, v] > 0 else float('inf') for u, v in edges}
                nx.set_edge_attributes(G, weights, 'weight')
            
                MB = get_metric_backbone_igraph(G)
            
            
                true_labels = list(nx.get_node_attributes(G, 'community').values())
                true_colors = ['red' if label == true_labels[0] else 'blue' for label in true_labels]

                SC = SpectralClustering(n_clusters=n_clusters, affinity='precomputed')

                A = get_Gaussian_weight_matrix(samples[:, col_slice], n_neighbors)

                pred_labels = SC.fit_predict(A)
                pred_colors = ['red' if label == pred_labels[0] else 'blue' for label in pred_labels]
            
                array_3d[n_neighbors, 'ARI_original', f'similarity_{i}'] = adjusted_rand_score(true_labels, pred_labels)
            
            
                A = nx.adjacency_matrix(MB, nodelist=[i for i in range(MB.number_of_nodes())], weight='proximity')
                A = scipy.sparse.csr_matrix(A)

                pred_labels = SC.fit_predict(A)
                pred_colors = ['red' if label == pred_labels[0] else 'blue' for label in pred_labels]
            
                array_3d[n_neighbors, 'ARI_MB', f'similarity_{i}'] = adjusted_rand_score(true_labels, pred_labels)
            
    
    
        axs[0].set_ylim(bottom=0, top=1)
        axs[0].plot(n_neighbors_LIST, array_3d.AVG_ARI_LIST(n_neighbors_LIST, 'ARI_original'))
        axs[0].errorbar(n_neighbors_LIST,  array_3d.AVG_ARI_LIST( n_neighbors_LIST, 'ARI_original'), yerr= array_3d.STD_ARI_LIST( n_neighbors_LIST, 'ARI_original'), fmt='o', label="Mean with Std Dev", alpha=0.5)
        axs[0].set_title('Original Graph')
    
        print(array_3d.STD_ARI_LIST(n_neighbors_LIST, 'ARI_MB'))
        print(array_3d)
    
        axs[1].set_ylim(0, 1)
        axs[1].plot(n_neighbors_LIST, array_3d.AVG_ARI_LIST(n_neighbors_LIST, 'ARI_MB'))
        axs[1].errorbar(n_neighbors_LIST,  array_3d.AVG_ARI_LIST( n_neighbors_LIST, 'ARI_MB'), yerr= array_3d.STD_ARI_LIST( n_neighbors_LIST, 'ARI_MB'), fmt='o', label="Mean with Std Dev", alpha=0.5)
        axs[1].set_title('Metric Backbone')
    
        for i in range(2):
            ax = axs[i]
            ax.set_xlabel('Number of nearest neighbors')
            ax.set_ylabel('ARI')
            ax.axis('on')
            ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)
            if i < 2:
                ax.legend(handles=[produce_patch(color='red', framework='gaussian', mu_x2=0), produce_patch(color='blue', framework='gaussian', mu_x2=mu_x2)])
            else:
                ax.legend(handles=[produce_patch(color='red', framework='ABBE',  plus_or_minus_one=1), produce_patch(color='blue', framework='ABBE', plus_or_minus_one=-1)])


    # ========================================================================



    return None


_static_assets = ["script_files","images/durrett.jpeg"]
_static_assets = {"/" + sa: Path(__file__).parent / sa for sa in _static_assets}

app = App(
    Path(__file__).parent / "script.html",
    server,
    static_assets=_static_assets,
)
